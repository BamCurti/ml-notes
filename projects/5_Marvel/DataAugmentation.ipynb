{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a3361bb",
   "metadata": {},
   "source": [
    "#### Instalamos las librerias faltantes e importamos las necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927cf7f2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-win_amd64.whl (35.4 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from opencv-python) (1.18.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.64\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99a5dd90",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-nightly\n",
      "  Using cached tf_nightly-2.10.0.dev20220512-cp38-cp38-win_amd64.whl (359.0 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tf-nightly) (21.3)\n",
      "Collecting tf-estimator-nightly~=2.10.0.dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages)\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\1234\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\1234\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.3.0 requires gast==0.3.3, but you have gast 0.4.0 which is incompatible.\n",
      "tensorflow 2.3.0 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.22.3 which is incompatible.\n",
      "tensorflow 2.3.0 requires scipy==1.4.1, but you have scipy 1.6.2 which is incompatible.\n",
      "tensorflow 2.3.0 requires tensorflow-estimator<2.4.0,>=2.3.0, but you have tensorflow-estimator 2.5.0 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached tf_estimator_nightly-2.10.0.dev2022051208-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tf-nightly) (1.13.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tf-nightly) (3.14.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tf-nightly) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tf-nightly) (1.42.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tf-nightly) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tf-nightly) (1.22.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tf-nightly) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tf-nightly) (3.10.0.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tf-nightly) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tf-nightly) (1.1.0)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tf-nightly) (58.0.4)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.25.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting keras-nightly~=2.10.0.dev\n",
      "  Using cached keras_nightly-2.10.0.dev2022051207-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.1-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\1234\\appdata\\roaming\\python\\python38\\site-packages (from tf-nightly) (1.16.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tf-nightly) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tf-nightly) (3.3.0)\n",
      "Collecting tb-nightly~=2.10.0.a\n",
      "  Using cached tb_nightly-2.10.0a20220511-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from astunparse>=1.6.0->tf-nightly) (0.35.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (1.6.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (1.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (2.27.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\1234\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\1234\\appdata\\roaming\\python\\python38\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.10.0.a->tf-nightly) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\1234\\appdata\\roaming\\python\\python38\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\1234\\appdata\\roaming\\python\\python38\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.10.0.a->tf-nightly) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\1234\\.conda\\envs\\deepenv\\lib\\site-packages (from packaging->tf-nightly) (3.0.4)\n",
      "Installing collected packages: absl-py, tf-estimator-nightly, tensorflow-io-gcs-filesystem, tb-nightly, libclang, keras-nightly, flatbuffers, tf-nightly\n",
      "Successfully installed absl-py-1.0.0 flatbuffers-1.12 keras-nightly-2.10.0.dev2022051207 libclang-14.0.1 tb-nightly-2.10.0a20220511 tensorflow-io-gcs-filesystem-0.25.0 tf-estimator-nightly-2.10.0.dev2022051208 tf-nightly-2.10.0.dev20220512\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-nightly --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "865372d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras.preprocessing.image as image\n",
    "#from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185e8f2",
   "metadata": {},
   "source": [
    "#### Creamos una carpeta nueva para guardar las imagenes divididas en categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6b2bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DG_folder='data_AU'\n",
    "images_increased = 5\n",
    "\n",
    "try:\n",
    "    os.mkdir(DG_folder)\n",
    "except:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e357de5b",
   "metadata": {},
   "source": [
    "#### Creamos una función sample con las características a variar en cada imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9deee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1d2859",
   "metadata": {},
   "source": [
    "#### Apuntamos a nuestra carpeta de imagenes original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc1d8432",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\1234\\Documents\\Repositorios\\AprendizajeMaquina_Equipo\\projects\\5_Marvel\\data\\MarvelDataSet\"\n",
    "data_dir_list = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5186b6f",
   "metadata": {},
   "source": [
    "#### Creamos una carpeta por cada personaje "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f5b5b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "width_shape, height_shape = 224, 244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7bd54de",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] No se puede crear un archivo que ya existe: 'data_AU\\\\AntMan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-c13052b3febe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage_folder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_dir_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDG_folder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mimg_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] No se puede crear un archivo que ya existe: 'data_AU\\\\AntMan'"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "num_images=0\n",
    "for image_folder in data_dir_list:\n",
    "    os.mkdir(DG_folder+'\\\\'+image_folder)\n",
    "    img_list=os.listdir(data_path+'\\\\'+image_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfad7fe9",
   "metadata": {},
   "source": [
    "#### Generamos y guardamos las imagenes aumentadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f9b6575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images generated for AntMan is 250\n",
      "images generated for BlackPanther is 250\n",
      "images generated for BlackWidow is 725\n",
      "images generated for CaptainAmerica is 435\n",
      "images generated for CaptainMarvel is 125\n",
      "images generated for Drax is 125\n",
      "images generated for DrStrange is 475\n",
      "images generated for Gamora is 245\n",
      "images generated for HawkEye is 125\n",
      "images generated for Hulk is 580\n",
      "images generated for Ironman is 605\n",
      "images generated for Loki is 255\n",
      "images generated for Quake is 125\n",
      "images generated for ScarlettWitch is 250\n",
      "images generated for Spiderman is 625\n",
      "images generated for Thor is 500\n",
      "images generated for Valkyrie is 125\n",
      "images generated for Vision is 125\n",
      "images generated for WinterSoldier is 125\n",
      "images generated for Yondu is 125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for image_folder in data_dir_list:\n",
    "    i=0\n",
    "    num_images=0\n",
    "    for image_file in os.listdir(data_path+'\\\\'+image_folder):\n",
    "        img_list=os.listdir(data_path+'\\\\'+image_folder)\n",
    "\n",
    "        img_path = data_path + '\\\\' + image_folder +  '\\\\' + image_file\n",
    "\n",
    "        imge=load_img(img_path)\n",
    "\n",
    "        imge=cv2.resize(image.img_to_array(imge), (width_shape, height_shape), interpolation = cv2.INTER_AREA)\n",
    "        x= imge/255\n",
    "        x=np.expand_dims(x,axis=0)\n",
    "        t=1\n",
    "        for output_batch in train_datagen.flow(x,batch_size=1):\n",
    "            a=image.img_to_array(output_batch[0])\n",
    "            imagen=output_batch[0,:,:]*255\n",
    "            imgfinal = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
    "            cv2.imwrite(DG_folder+'\\\\'+image_folder +\"/%i%i.jpg\"%(i,t), imgfinal) \n",
    "            t+=1\n",
    "\n",
    "            num_images+=1\n",
    "            if t>images_increased:\n",
    "                break\n",
    "        i+=1\n",
    "    print(\"images generated for\",image_folder ,\"is\",num_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
